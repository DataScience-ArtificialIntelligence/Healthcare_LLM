{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df08a7ff-4021-4689-b49f-cf0119a9c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\surya\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f92e8c-5ece-46b1-ba44-e6c4c51833b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"pubmed_qa\"\n",
    "DATASET_SUBSET = \"pqa_labeled\"\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "OUTPUT_DIR = \"./llama-3.2-1B-pubmedqa\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 5\n",
    "SAVE_STEPS = 1000\n",
    "HF_TOKEN = \"MY ACCESS TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3feba236-b8d0-42df-81fe-22804c798ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2afe34c-b7e7-4716-8ba4-e5ef8501fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, DATASET_SUBSET)\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1e888a-af9f-4706-b992-0c8aba0038b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['pubid', 'question', 'context', 'long_answer', 'final_decision'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9f8726-b3d4-4d33-bde6-b3e10c2c66ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pubid                                           question  \\\n",
      "0  21645374  Do mitochondria play a role in remodelling lac...   \n",
      "1  16418930  Landolt C and snellen e acuity: differences in...   \n",
      "2   9488747  Syncope during bathing in infants, a pediatric...   \n",
      "3  17208539  Are the long-term results of the transanal pul...   \n",
      "4  10808977  Can tailored interventions increase mammograph...   \n",
      "\n",
      "                                             context  \\\n",
      "0  {'contexts': ['Programmed cell death (PCD) is ...   \n",
      "1  {'contexts': ['Assessment of visual acuity dep...   \n",
      "2  {'contexts': ['Apparent life-threatening event...   \n",
      "3  {'contexts': ['The transanal endorectal pull-t...   \n",
      "4  {'contexts': ['Telephone counseling and tailor...   \n",
      "\n",
      "                                         long_answer final_decision  \n",
      "0  Results depicted mitochondrial dynamics in viv...            yes  \n",
      "1  Using the charts described, there was only a s...             no  \n",
      "2  \"Aquagenic maladies\" could be a pediatric form...            yes  \n",
      "3  Our long-term study showed significantly bette...             no  \n",
      "4  The effects of the intervention were most pron...            yes  \n",
      "Index(['pubid', 'question', 'context', 'long_answer', 'final_decision'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f606e9-24b2-4cc3-a3c6-37a0ba91182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(ds):\n",
    "    print(f\"Dataset size: {len(ds['train'])}\")\n",
    "    print(f\"Dataset columns: {ds['train'].column_names}\")\n",
    "    print(f\"Sample entry: {ds['train'][0]}\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773589b2-4016-4329-ad27-a4c899506183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1000\n",
      "Dataset columns: ['pubid', 'question', 'context', 'long_answer', 'final_decision']\n",
      "Sample entry: {'pubid': 21645374, 'question': 'Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?', 'context': {'contexts': ['Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants.', 'The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (ΔΨm). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells.'], 'labels': ['BACKGROUND', 'RESULTS'], 'meshes': ['Alismataceae', 'Apoptosis', 'Cell Differentiation', 'Mitochondria', 'Plant Leaves'], 'reasoning_required_pred': ['y', 'e', 's'], 'reasoning_free_pred': ['y', 'e', 's']}, 'long_answer': 'Results depicted mitochondrial dynamics in vivo as PCD progresses within the lace plant, and highlight the correlation of this organelle with other organelles during developmental PCD. To the best of our knowledge, this is the first report of mitochondria and chloroplasts moving on transvacuolar strands to form a ring structure surrounding the nucleus during developmental PCD. Also, for the first time, we have shown the feasibility for the use of CsA in a whole plant system. Overall, our findings implicate the mitochondria as playing a critical and early role in developmentally regulated PCD in the lace plant.', 'final_decision': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "dataset = explore_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d94f36-3f10-4c10-a728-7cccf1774587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pubmed_qa(examples):\n",
    "    formatted_prompts = []\n",
    "    for i in range(len(examples[\"pubid\"])):\n",
    "        question = examples[\"question\"][i]\n",
    "        context = examples[\"context\"][i][\"contexts\"][0] if examples[\"context\"][i][\"contexts\"] else \"\"\n",
    "        \n",
    "        label = examples[\"final_decision\"][i]\n",
    "        \n",
    "        if label == \"yes\":\n",
    "            answer = f\"Yes. Based on the medical literature: {context}\"\n",
    "        elif label == \"no\":\n",
    "            answer = f\"No. Based on the medical literature: {context}\"\n",
    "        else:  # maybe\n",
    "            answer = f\"The evidence is inconclusive. Based on the medical literature: {context}\"\n",
    "        \n",
    "        instruction = f\"Answer the following medical question based on evidence from medical literature: {question}\"\n",
    "        \n",
    "        formatted_prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are a helpful medical assistant that provides evidence-based answers.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n{answer}<|eot_id|>\"\n",
    "        formatted_prompts.append(formatted_prompt)\n",
    "    \n",
    "    return {\"formatted_text\": formatted_prompts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629bf554-83a9-4ecb-95e9-b5235402f8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76456c5e2d834ecc8a16db0666da1a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset processed.\n",
      "Sample processed entry: {'formatted_text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are a helpful medical assistant that provides evidence-based answers.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nAnswer the following medical question based on evidence from medical literature: Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\nYes. Based on the medical literature: Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants.<|eot_id|>'}\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = dataset.map(\n",
    "    preprocess_pubmed_qa,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names  # Remove original columns\n",
    ")\n",
    "print(\"Dataset processed.\")\n",
    "print(f\"Sample processed entry: {processed_dataset['train'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5322f5c-23e5-4002-a586-40295595135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = processed_dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "train_dataset = processed_dataset[\"train\"]\n",
    "eval_dataset = processed_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7182925e-5534-4f3a-a097-1569e45e0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"formatted_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea390127-81d3-43c1-8d2d-02b6f6a9e82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f644408f60640df99b819a09b02ae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f9ae2f53534dc49ad88ebd82be578f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"formatted_text\"])\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True, remove_columns=[\"formatted_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45b6f72-0cd5-481a-a394-244990276e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_eval.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c304e0a-357a-4ba7-bf16-6297e876983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up model...\")\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    token=HF_TOKEN,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c796f5-3669-4317-9858-a20fd8b2b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca95c1ff-c1f7-4a1f-95b8-c08571296956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,703,936 || all params: 1,237,518,336 || trainable%: 0.1377\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  # Shows what percentage of parameters will be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d836c7-d080-4c3d-a9c1-bf93c63a3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=SAVE_STEPS,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=3,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84be9406-b123-486b-9061-06ac8205559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # We're doing causal language modeling, not masked\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "781ff480-6d76-4c2c-8552-f9fb50727e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afbfdab3-9591-4814-8c35-bc23e2a4739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 4:02:05, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=3.856314195905413, metrics={'train_runtime': 14636.408, 'train_samples_per_second': 0.307, 'train_steps_per_second': 0.01, 'total_flos': 1.3081021469687808e+16, 'train_loss': 3.856314195905413, 'epoch': 4.8533333333333335})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3db343fa-719e-4183-9259-8c583d31cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./llama-3.2-1B-pubmedqa/final\\\\tokenizer_config.json',\n",
       " './llama-3.2-1B-pubmedqa/final\\\\special_tokens_map.json',\n",
       " './llama-3.2-1B-pubmedqa/final\\\\tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Saving model...\")\n",
    "model.save_pretrained(f\"{OUTPUT_DIR}/final\")\n",
    "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "516edd71-c331-43d3-b431-02317edb7cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 3.56388783454895, 'eval_runtime': 34.1247, 'eval_samples_per_second': 2.93, 'eval_steps_per_second': 0.733, 'epoch': 4.8533333333333335}\n",
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "print(\"Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc819212-ba63-43fc-b97d-d08114adef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Statins have been shown to lower cholesterol levels, reduce the risk of heart attack, stroke, and heart failure, and improve overall cardiovascular health.\n",
      "\n",
      "Key points:\n",
      "\n",
      "*   Statins work by inhibiting the enzyme HMG-CoA reductase, which is involved in the production of cholesterol in the liver.\n",
      "*   By reducing cholesterol levels, statins can help to lower the risk of heart attack, stroke, and heart failure.\n",
      "*   Statins can also help to improve blood lipid profiles, which can reduce the risk of cardiovascular disease.\n",
      "*   In addition to lowering cholesterol, statins can help to improve blood vessel function and reduce inflammation in the blood vessels.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "model_path = \"./llama-3.2-1B-pubmedqa/final\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    print(f\"Set pad_token_id to eos_token_id: {tokenizer.pad_token_id}\")\n",
    "\n",
    "def ask_question(question, max_length=512):\n",
    "    prompt = f\"Question: {question}\\nAnswer:\"\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=model.config.max_position_embeddings\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],  # Pass attention mask\n",
    "            max_length=max_length,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id  # Explicitly pass pad_token_id\n",
    "        )\n",
    "    \n",
    "    outputs = outputs.cpu()\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = response.split(\"Answer:\")[1].strip() if \"Answer:\" in response else response\n",
    "\n",
    "    return answer\n",
    "\n",
    "question = \"What are the effects of statins on cardiovascular health?\"\n",
    "answer = ask_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a7ed6-9ac3-41c4-a4fe-01a18ed21aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
